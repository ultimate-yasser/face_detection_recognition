function runFaceDetection()
    cam = initializeWebcam();
    videoPlayer = initializeVideoPlayer(cam);
    runLoop = true;

    isCheckOval = true;
    eyeDetector = vision.CascadeObjectDetector('EyePairSmall');

    selectedObject = [];  % Initialize variable to store the selected object
    previousBbox = [];  % Store the previous bounding box for tracking

    while runLoop
        frame = snapshot(cam);
        objects = detectSkinObjects(frame);

        for i = 1:length(objects)
            objects(i).points = 0;

            if isCheckOval && isOvalLikeShape(objects(i), frame)
                objects(i).points = objects(i).points + 1;
            end

            if containsEyes(objects(i), frame, eyeDetector)
                objects(i).points = objects(i).points + 1;
            end
        end

        if isempty(objects)
            step(videoPlayer, frame);
            runLoop = isOpen(videoPlayer);
            continue;
        end

        % If no object has been selected yet, select the one with the highest score (points)
        if isempty(selectedObject)
            maxPts = max([objects.points]);
            bestObjects = objects([objects.points] == maxPts);

            % If there are multiple objects with the same score, choose the largest one
            if length(bestObjects) > 1
                areas = arrayfun(@(obj) prod(obj.BoundingBox(3:4)), bestObjects);  % Calculate area
                [~, idx] = max(areas);  % Find the index of the largest object
                selectedObject = bestObjects(idx);  % Select the largest object
                previousBbox = selectedObject.BoundingBox;  % Store the previous bounding box
            else
                selectedObject = bestObjects(1);  % Select the object with the highest points
                previousBbox = selectedObject.BoundingBox;  % Store the previous bounding box
            end
        else
            % Update the selected object's position based on the previously selected object
            selectedObject = trackObject(selectedObject, objects, previousBbox);
            previousBbox = selectedObject.BoundingBox;  % Update previous bounding box
        end

        % Draw the bounding box around the selected object (locked object)
        if ~isempty(selectedObject)
            bbox = selectedObject.BoundingBox;
            frame = insertShape(frame, 'Rectangle', bbox, 'LineWidth', 3, 'Color', 'green');
        end

        step(videoPlayer, frame);
        runLoop = isOpen(videoPlayer);
    end

    clear cam;
    release(videoPlayer);
end

function cam = initializeWebcam()
    cam = webcam();
end

function videoPlayer = initializeVideoPlayer(cam)
    frame = snapshot(cam);
    frameSize = size(frame);
    videoPlayer = vision.VideoPlayer('Position', [100 100 [frameSize(2), frameSize(1)] + 30]);
end

function objects = detectSkinObjects(frame)
    imgYCbCr = rgb2ycbcr(frame);
    Cb = imgYCbCr(:,:,2);
    Cr = imgYCbCr(:,:,3);

    % Filter objects based on skin tone color (human skin color range in YCbCr)
    skinMask = (Cb >= 77 & Cb <= 127) & (Cr >= 133 & Cr <= 173);  % Human skin tone range
    skinMask = medfilt2(skinMask, [5 5]);
    skinMask = imfill(skinMask, 'holes');
    skinMask = bwareaopen(skinMask, 100);  % Remove small regions

    stats = regionprops(skinMask, 'BoundingBox', 'Area', 'Eccentricity');
    minArea = 1500;  % Minimum size set to 1500 pixels

    objects = struct('BoundingBox', {}, 'Eccentricity', {}, 'points', {});
    for i = 1:length(stats)
        if stats(i).Area > minArea
            objects(end+1).BoundingBox = stats(i).BoundingBox;
            objects(end).Eccentricity = stats(i).Eccentricity;
            objects(end).points = 0;
        end
    end
end

function isValid = isOvalLikeShape(obj, frame)
    bbox = obj.BoundingBox;
    width = round(bbox(3));
    height = round(bbox(4));
    x = round(bbox(1));
    y = round(bbox(2));

    [H, W, ~] = size(frame);
    x = max(1, min(x, W));
    y = max(1, min(y, H));
    width = max(1, min(width, W - x));
    height = max(1, min(height, H - y));

    roi = frame(y:y+height-1, x:x+width-1, :);
    grayROI = rgb2gray(roi);
    bw = imbinarize(grayROI, 'adaptive');
    bw = imfill(bw, 'holes');
    bw = bwareafilt(bw, 1);  % Largest object inside ROI

    props = regionprops(bw, 'Eccentricity', 'Solidity', 'Extent', ...
                        'MajorAxisLength', 'MinorAxisLength', 'Area');

    if isempty(props)
        isValid = false;
        return;
    end

    % Read the geometric properties
    eccentricity = props(1).Eccentricity;
    solidity = props(1).Solidity;
    extent = props(1).Extent;
    majorAxis = props(1).MajorAxisLength;
    minorAxis = props(1).MinorAxisLength;
    area = props(1).Area;

    axisRatio = minorAxis / majorAxis;
    brightness = mean(grayROI(:));

    % Check if the shape is oval-like and not too bright
    isValid = ...
        eccentricity < 0.85 && ...  % Reject non-oval shapes
        solidity > 0.9 && ...       % Higher solidity for human-like shapes
        extent >= 0.5 && extent <= 0.85 && ...
        axisRatio >= 0.7 && axisRatio <= 1.3 && ...  % Aspect ratio of an oval
        brightness < 220 && ...  % Reject overly bright areas
        isSkinColor(roi);  % Check if the ROI contains human skin color
end

function isSkin = isSkinColor(roi)
    % Check if the colors in the ROI are human skin color (based on YCbCr)
    imgYCbCr = rgb2ycbcr(roi);
    Cb = imgYCbCr(:,:,2);
    Cr = imgYCbCr(:,:,3);

    % Human skin color range in Cb and Cr
    skinMask = (Cb >= 77 & Cb <= 127) & (Cr >= 133 & Cr <= 173);  % Human skin tone range
    skinRatio = sum(skinMask(:)) / numel(skinMask);

    % If more than 70% of the ROI is skin color, consider it a valid skin object
    isSkin = skinRatio > 0.7;
end

function found = containsEyes(obj, frame, eyeDetector)
    bbox = obj.BoundingBox;
    width = round(bbox(3));
    height = round(bbox(4));
    x = round(bbox(1));
    y = round(bbox(2));

    [H, W, ~] = size(frame);
    x = max(1, min(x, W));
    y = max(1, min(y, H));
    width = max(1, min(width, W - x));
    height = max(1, min(height, H - y));

    roi = frame(y:y+height-1, x:x+width-1, :);
    eyeBBoxes = step(eyeDetector, roi);

    found = ~isempty(eyeBBoxes);
end

function selectedObject = trackObject(selectedObject, objects, previousBbox)
    % Track the selected object by comparing its bounding box in the current frame
    maxIoU = 0;  % Maximum Intersection over Union (IoU)
    for i = 1:length(objects)
        IoU = bboxOverlapRatio(selectedObject.BoundingBox, objects(i).BoundingBox);
        if IoU > maxIoU
            maxIoU = IoU;
            selectedObject = objects(i);  % Update the selected object
        end
    end
end
